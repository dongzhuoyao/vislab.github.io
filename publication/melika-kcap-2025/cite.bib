@inproceedings{10.1145/3731443.3771357,
author = {Ayoughi, Melika and Mettes, Pascal and Groth, Paul},
title = {Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring},
year = {2025},
isbn = {9798400718670},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3731443.3771357},
doi = {10.1145/3731443.3771357},
abstract = {Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers.},
booktitle = {Proceedings of the 13th Knowledge Capture Conference 2025},
pages = {123â€“130},
numpages = {8},
keywords = {Ontology Engineering, Ontology Design, Hyperbolic Learning, Hierarchical Representation, Machine Learning},
location = {
},
series = {K-CAP '25}
}